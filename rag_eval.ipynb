{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.embeddings import HuggingFaceEmbedding, OpenAIEmbedding, BedrockEmbedding\n",
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "from IPython.display import display\n",
    "from llama_index.indices.query.schema import QueryBundle\n",
    "import chromadb\n",
    "from llama_index.evaluation import RetrieverEvaluator\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import torch\n",
    "import os\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "from llama_index.embeddings.cohereai import CohereEmbedding\n",
    "from api_key import oai_api_key, cohere_api_key\n",
    "import openai\n",
    "import boto3\n",
    "\n",
    "dataset = load_dataset(\"Finnish-NLP/wikipedia_20230501_fi_cleaned\")\n",
    "\n",
    "# set up OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] =  oai_api_key\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "# Set up Bedrock\n",
    "session = boto3.Session(profile_name='default')\n",
    "\n",
    "bedrock_client = session.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"eu-central-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58e2553d7d4423ead82af90900e3b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Lets make 10 questions first for 100 samples and see how eval works with few simple embedding models and take if from there\n",
    "samples = 50\n",
    "dataset = dataset[\"train\"].select([i for i in range(samples)])\n",
    "\n",
    "# Lets reset index with pandas to simplify things later\n",
    "dataset_pd = dataset.to_pandas()\n",
    "dataset_pd[\"id\"] = [i for i in range(samples)]\n",
    "dataset = Dataset.from_pandas(dataset_pd)\n",
    "\n",
    "# Some embedding models mighgt have smaller context size so lets limit size in first testing to 256 tokens or 200 words\n",
    "def take_first_256_words(row):\n",
    "    row[\"text\"] = ' '.join(row[\"text\"].split(' ')[:256])\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(take_first_256_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test object (Documents or Textnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create test nodes/documents\n",
    "# Nodes are first class citizens and will be used for testing\n",
    "from llama_index.schema import Document, TextNode\n",
    "documents_all = []\n",
    "nodes_all = []\n",
    "for i, sample in enumerate(dataset):\n",
    "    documents_all.append(Document(\n",
    "        text=sample[\"text\"],\n",
    "        id_=sample[\"id\"],\n",
    "    )\n",
    "    )\n",
    "    \n",
    "for i, sample in enumerate(dataset):\n",
    "    nodes_all.append(TextNode(\n",
    "        text=sample[\"text\"],\n",
    "        id_=sample[\"id\"],\n",
    "    )\n",
    "    )\n",
    "\n",
    "corpus = {sample[\"id\"]: sample[\"text\"] for sample in dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Question creation with llm based on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Automatic question creation\n",
    "\n",
    "from llama_index.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# Prompt to generate questions\n",
    "qa_generate_prompt_tmpl = \"\"\"\\\n",
    "Saat seuraavaksi tietoa kontekstiksi.\n",
    "\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "\n",
    "Annettuna edeltävä teksti, tehtävänäsi on luoda kysymyksiä perustuen vain yllä annettuun tietoon.\n",
    "\n",
    "Olet Professori. Tehtävänäsi on luoda \\\n",
    "{num_questions_per_chunk} kysymystä tulevaan \\\n",
    "kokeeseen/tentiin. Kysymysten tulisi olla monipuolisia \\\n",
    "ja kattavasti koko aineistosta. Kysymykset eivät saa sisältää vaihtoehtoja, eikä alkaa tekstillä kysymys 1 / kysymys 2. \\\n",
    "Kysymykset tulee rajoittua vain annettuun tekstiin. Tämä on erittäin tärkeä tehtävä.\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create up to x questions\n",
    "\n",
    "amount_of_questions = 10\n",
    "ids_picked = []\n",
    "max_len = len(nodes_all)\n",
    "assert amount_of_questions < max_len * 0.5\n",
    "while len(ids_picked) < amount_of_questions:\n",
    "    ids_picked.append(random.randint(0,max_len-1))\n",
    "    ids_picked = list(set(ids_picked))\n",
    "    \n",
    "\n",
    "question_nodes = [nodes_all[i] for i in ids_picked]\n",
    "\n",
    "llm = OpenAI(temperature=0, api_key=openai.api_key)\n",
    "\n",
    "# qa_dataset = generate_question_context_pairs(\n",
    "#     question_nodes, llm=llm, num_questions_per_chunk=1, qa_generate_prompt_tmpl=qa_generate_prompt_tmpl\n",
    "# )\n",
    "\n",
    "questions = []\n",
    "for question_node in question_nodes:\n",
    "    llm_response = llm.complete(qa_generate_prompt_tmpl.format(context_str=question_node.text, num_questions_per_chunk=1), max_tokens=256)\n",
    "    questions.append(llm_response.text)\n",
    "    \n",
    "testing_questions_llm_created = {ids_picked[i]: questions[i] for i in range(len(ids_picked))}\n",
    "relevant_docs_llm_created = {id_picked:  [id_picked] for id_picked in ids_picked}\n",
    "\n",
    "assert len(questions) == amount_of_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{35: 'Mikä on Ateenan väestötiheys?', 4: 'Mikä on AU-tunnus ja mitä se tarkoittaa astronomiassa?', 7: 'Mikä oli Nasan avaruussukkulalentojen kokonaismäärä ja kuinka monta lentoa päättyi onnettomuuteen?', 42: 'Miksi Alfred Hitchcockia pidetään jännityselokuvan mestarina ja mitkä ovat hänen tunnetuimmat elokuvansa?', 12: 'Mikä on fysikaalisen avaruuden määritelmä klassisessa fysiikassa?', 13: 'Miten avoimien joukkojen käsite liittyy topologian keskeisiin käsitteisiin, kuten raja-arvoon, jatkuvuuteen ja yhtenäisyyteen?', 25: 'Miten arkkitehtuurin toteuttaminen eroaa muista taiteista?', 26: 'Mikä on antropologian yhteys muihin tieteenlajeihin ja millä tavoin antropologia tutkii ihmisen biologiaa?', 28: 'Mikä on atomiytimen rakenne ja mitä hiukkasia se sisältää?', 29: 'Mikä on analogisen teknologian etu verrattuna digitaaliseen teknologiaan varhaisessa kehitysvaiheessa?'}\n",
      "{35: [35], 4: [4], 7: [7], 42: [42], 12: [12], 13: [13], 25: [25], 26: [26], 28: [28], 29: [29]}\n"
     ]
    }
   ],
   "source": [
    "print(testing_questions_llm_created)\n",
    "print(relevant_docs_llm_created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual test questions creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now i run this one by one and try to come up with one question per sample to have at least one question for 10 documents that I am expecting to hit\n",
    "# import random\n",
    "# nodes_with_no_questions = [i for i in range(len(nodes_all)) if i not in ids_picked]\n",
    "\n",
    "# i = random.choice(nodes_with_no_questions)\n",
    "# i = 130\n",
    "# print(dataset[i][\"title\"])\n",
    "# print(int(nodes_all[i].id_))\n",
    "# print(nodes_all[i].text)\n",
    "# for line in dataset[i][\"text\"].split('.'):\n",
    "#     print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL QUESTION CREATION\n",
    "# id, question\n",
    "\n",
    "manual=True\n",
    "\n",
    "if manual:\n",
    "    \n",
    "    testing_questions = [(41, \"Miten selittäisi mitä algoritmi tarkoittaa?\"),\n",
    "                        (73, \"Missä maassa sijaitsee Gentin satama?\"),\n",
    "                        (100, \"Paljonko dieselveturi painaa\"),\n",
    "                        (79, \"Mitä Eteläisiä aikakausia tai siis dynastioita Kiinassa oli?\"),\n",
    "                        (130, \"Millä keinotekoisella kielellä on noin tuhat puhujaa?\"),\n",
    "                        ]\n",
    "\n",
    "    testing_questions = [testing_question for testing_question in testing_questions if testing_question[0] < samples]\n",
    "\n",
    "    # Do same kind of structure as in the example at https://colab.research.google.com/drive/1TxDVA__uimVPOJiMEQgP5fwHiqgKqm4-?usp=sharing#\n",
    "    filtered_questions_manual = {q[0]:  q[1] for q in testing_questions}\n",
    "    filtered_relevant_docs_manual = {q[0]:  [q[0]] for q in testing_questions}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine LLM created and manually created questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets combine\n",
    "if manual:\n",
    "    questions = {**filtered_questions_manual, **testing_questions_llm_created}\n",
    "    relevant_docs= {**filtered_relevant_docs_manual, **relevant_docs_llm_created}\n",
    "\n",
    "    # Define QA dataset\n",
    "    qa_dataset = EmbeddingQAFinetuneDataset(\n",
    "                queries=questions, # Dict jossa avaimena id, valuena kysymys jolla aineisto pitäisi löytyä\n",
    "                corpus=corpus, # Dict jossa avaimena id, valuena teksti\n",
    "                relevant_docs=relevant_docs # Dict jossa avaimena query id ja valuena sitä mätsäävien tekstien id:t listana\n",
    "    )\n",
    "else:\n",
    "    questions = {**testing_questions_llm_created}\n",
    "    relevant_docs= {**relevant_docs_llm_created}\n",
    "\n",
    "    # Define QA dataset\n",
    "    qa_dataset = EmbeddingQAFinetuneDataset(\n",
    "                queries=questions, # Dict jossa avaimena id, valuena kysymys jolla aineisto pitäisi löytyä\n",
    "                corpus=corpus, # Dict jossa avaimena id, valuena teksti\n",
    "                relevant_docs=relevant_docs # Dict jossa avaimena query id ja valuena sitä mätsäävien tekstien id:t listana\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_hit_rate(retrieval_dict):\n",
    "    \"\"\"\n",
    "    Calculate the hit rate for each target document id and its corresponding list of retrieved ids.\n",
    "\n",
    "    Parameters:\n",
    "    - retrieval_dict (dict): Dictionary with keys as target document ids and values as lists of retrieved document ids.\n",
    "\n",
    "    Returns:\n",
    "    - hit_rates (dict): Dictionary with target document ids as keys and hit rates as values.\n",
    "    \"\"\"\n",
    "    hit_rates = []\n",
    "    for target_id, retrieved_ids in retrieval_dict.items():\n",
    "        hit_rate = 1 if target_id in retrieved_ids else 0\n",
    "        hit_rates.append(hit_rate)\n",
    "\n",
    "    return np.mean(hit_rates)\n",
    "\n",
    "\n",
    "def calculate_mrr(retrieval_dict):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Reciprocal Rank (MRR) for each target document id and its corresponding list of retrieved ids.\n",
    "\n",
    "    Parameters:\n",
    "    - retrieval_dict (dict): Dictionary with keys as target document ids and values as lists of retrieved document ids.\n",
    "\n",
    "    Returns:\n",
    "    - mrrs (dict): Dictionary with target document ids as keys and MRRs as values.\n",
    "    \"\"\"\n",
    "    mrrs = []\n",
    "    for target_id, retrieved_ids in retrieval_dict.items():\n",
    "        if target_id in retrieved_ids:\n",
    "            rank = retrieved_ids.index(target_id) + 1\n",
    "            mrr = 1 / rank\n",
    "        else:\n",
    "            mrr = 0\n",
    "        mrrs.append(mrr)\n",
    "    mrr = np.mean(mrrs)\n",
    "    return mrr\n",
    "\n",
    "\n",
    "\n",
    "def get_query_results(qa_dataset, querymachine):\n",
    "    targets = list(qa_dataset.queries.keys())\n",
    "    querylist = list(qa_dataset.queries.values())\n",
    "    retrieved_dict = {}\n",
    "\n",
    "    query_time_start = datetime.datetime.now()\n",
    "    for i, query in enumerate(querylist):\n",
    "        q_retrieved_ids = []\n",
    "        retrieved_nodes = querymachine.retrieve(QueryBundle(query))\n",
    "        for node in retrieved_nodes:\n",
    "            q_retrieved_ids.append(node.id_)\n",
    "        retrieved_dict[targets[i]] = q_retrieved_ids\n",
    "    \n",
    "    query_time_end = datetime.datetime.now()\n",
    "    query_time_total = (query_time_end-query_time_start).total_seconds()\n",
    "    query_time_single = query_time_total / len(querylist)\n",
    "\n",
    "    return retrieved_dict, query_time_total, query_time_single\n",
    "\n",
    "\n",
    "def form_results_df(retrieval_results, model_name, reranker_name, embedding_time, embedding_time_single, retrieval_time, retrieval_time_single):\n",
    "    result_dict = {}\n",
    "    hit_rate = calculate_hit_rate(retrieval_results)\n",
    "    mrr = calculate_mrr(retrieval_results)\n",
    "    df = pd.DataFrame([[mrr, hit_rate]], columns = ['mrr', 'hit_rate'])\n",
    "    df[\"model_name\"] = model_name\n",
    "    df[\"reranker_name\"] = reranker_name\n",
    "    df[\"embedding_time\"] = embedding_time\n",
    "    df[\"embedding_time_single\"] = embedding_time_single\n",
    "    df[\"retrieval_time\"] = retrieval_time\n",
    "    df[\"retrieval_time_single\"] = retrieval_time_single\n",
    "    result_dict[\"mrr\"] = mrr\n",
    "    result_dict[\"hit_rate\"] = hit_rate\n",
    "    result_dict[\"model_name\"] = model_name\n",
    "    result_dict[\"reranker_name\"] = reranker_name\n",
    "    result_dict[\"embedding_time\"] = embedding_time\n",
    "    result_dict[\"embedding_time_single\"] = embedding_time_single\n",
    "    result_dict[\"retrieval_time\"] = retrieval_time\n",
    "    result_dict[\"retrieval_time_single\"] = retrieval_time_single\n",
    "    \n",
    "    return df, result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create client and a new collection\n",
    "def embed_data_and_def_retriever(embed_model, reranker=None, embed_model_name=None):\n",
    "    \n",
    "    chroma_client = chromadb.EphemeralClient()\n",
    "    try:\n",
    "        chroma_collection = chroma_client.delete_collection(embed_model_name)\n",
    "        chroma_collection = chroma_client.create_collection(embed_model_name)\n",
    "        print(\"found existing collection\")\n",
    "    except Exception as e:\n",
    "        chroma_collection = chroma_client.create_collection(embed_model_name)\n",
    "        print(\"Created new collection\")\n",
    "\n",
    "\n",
    "    # set up ChromaVectorStore and load in data\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    \n",
    "\n",
    "    # Define context etch objects for  retrieval\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=None)\n",
    "    print(f\"CREATING EMBEDDING DB WITH EMBEDDING MODEL: {embed_model_name}, reranker is {reranker}\")\n",
    "    start = datetime.datetime.now()\n",
    "    index = VectorStoreIndex(nodes=nodes_all, storage_context=storage_context, service_context=service_context, show_progress=True)\n",
    "    end = datetime.datetime.now()\n",
    "    embedding_time = (end-start).total_seconds()\n",
    "    embedding_time_single = embedding_time / len(nodes_all)\n",
    "\n",
    "    \n",
    "    # Define retriever\n",
    "    if reranker != None:\n",
    "        print(f\"Reranker is not none, adding reranker\")\n",
    "        retriever = index.as_query_engine(similarity_top_k=5, node_postprocessors=[reranker])\n",
    "        return retriever, index, embedding_time, embedding_time_single\n",
    "    \n",
    "    else:\n",
    "        print(f\"Reranker is None\")\n",
    "        retriever = index.as_query_engine(similarity_top_k=5)\n",
    "        return retriever, index, embedding_time, embedding_time_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_results(qa_dataset, querymachine):\n",
    "    targets = list(qa_dataset.queries.keys())\n",
    "    querylist = list(qa_dataset.queries.values())\n",
    "    retrieved_dict = {}\n",
    "\n",
    "    query_time_start = datetime.datetime.now()\n",
    "    for i, query in enumerate(querylist):\n",
    "        q_retrieved_ids = []\n",
    "        retrieved_nodes = querymachine.retrieve(QueryBundle(query))\n",
    "        for node in retrieved_nodes:\n",
    "            q_retrieved_ids.append(node.id_)\n",
    "        retrieved_dict[targets[i]] = q_retrieved_ids\n",
    "    \n",
    "    query_time_end = datetime.datetime.now()\n",
    "    query_time_total = (query_time_end-query_time_start).total_seconds()\n",
    "    query_time_single = query_time_total / len(querylist)\n",
    "\n",
    "    return retrieved_dict, query_time_total, query_time_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda as device\n",
      "--------------------------------------------------\n",
      "model_to_try is: intfloat/multilingual-e5-base\n",
      "reranker is: BAAI/bge-reranker-base\n",
      "found existing collection\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "CREATING EMBEDDING DB WITH EMBEDDING MODEL: intfloat_multilingual_e5_base, reranker is callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x000001F554AA77C0> model='BAAI/bge-reranker-base' top_n=3 device='cuda:0' keep_retrieval_score=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14c48fb2c51474a80a80f84f93d5772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker is not none, adding reranker\n",
      "Results: hit_rate: 1.0, mrr: 1.0\n",
      "model_to_try is: intfloat/multilingual-e5-base\n",
      "reranker is: None\n",
      "Results: hit_rate: 1.0, mrr: 0.9545454545454546\n",
      "--------------------------------------------------\n",
      "model_to_try is: intfloat/multilingual-e5-base\n",
      "reranker is: Cohere\n",
      "Results: hit_rate: 1.0, mrr: 1.0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "model_to_try is: TurkuNLP/sbert-cased-finnish-paraphrase\n",
      "reranker is: BAAI/bge-reranker-base\n",
      "found existing collection\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "CREATING EMBEDDING DB WITH EMBEDDING MODEL: TurkuNLP_sbert_cased_finnish_paraphrase, reranker is callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x000001F28EDEAF50> model='BAAI/bge-reranker-base' top_n=3 device='cuda:0' keep_retrieval_score=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51046dbc22b54bb1aec94098ff64ff82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker is not none, adding reranker\n",
      "Results: hit_rate: 1.0, mrr: 1.0\n",
      "model_to_try is: TurkuNLP/sbert-cased-finnish-paraphrase\n",
      "reranker is: None\n",
      "Results: hit_rate: 1.0, mrr: 0.9090909090909091\n",
      "--------------------------------------------------\n",
      "model_to_try is: TurkuNLP/sbert-cased-finnish-paraphrase\n",
      "reranker is: Cohere\n",
      "Results: hit_rate: 1.0, mrr: 1.0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "model_to_try is: text-embedding-3-small\n",
      "reranker is: BAAI/bge-reranker-base\n",
      "found existing collection\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "CREATING EMBEDDING DB WITH EMBEDDING MODEL: text_embedding_3_small, reranker is callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x000001F2736EDFC0> model='BAAI/bge-reranker-base' top_n=3 device='cuda:0' keep_retrieval_score=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be814f1069e74de9b8ac1da3e85ba287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker is not none, adding reranker\n",
      "Results: hit_rate: 1.0, mrr: 1.0\n",
      "model_to_try is: text-embedding-3-small\n",
      "reranker is: None\n",
      "Results: hit_rate: 1.0, mrr: 1.0\n",
      "--------------------------------------------------\n",
      "model_to_try is: text-embedding-3-small\n",
      "reranker is: Cohere\n",
      "Results: hit_rate: 1.0, mrr: 1.0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "model_to_try is: embed-multilingual-v3.0\n",
      "reranker is: BAAI/bge-reranker-base\n",
      "found existing collection\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "CREATING EMBEDDING DB WITH EMBEDDING MODEL: embed_multilingual_v3.0, reranker is callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x000001F37E408E80> model='BAAI/bge-reranker-base' top_n=3 device='cuda:0' keep_retrieval_score=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0224ae8c7c7340b88d74df4a26fdd56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker is not none, adding reranker\n",
      "Results: hit_rate: 1.0, mrr: 1.0\n",
      "model_to_try is: embed-multilingual-v3.0\n",
      "reranker is: None\n",
      "Results: hit_rate: 1.0, mrr: 0.9545454545454546\n",
      "--------------------------------------------------\n",
      "model_to_try is: embed-multilingual-v3.0\n",
      "reranker is: Cohere\n",
      "Results: hit_rate: 1.0, mrr: 1.0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "model_to_try is: Bedrock\n",
      "reranker is: BAAI/bge-reranker-base\n",
      "found existing collection\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "CREATING EMBEDDING DB WITH EMBEDDING MODEL: Bedrock, reranker is callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x000001F37E37F130> model='BAAI/bge-reranker-base' top_n=3 device='cuda:0' keep_retrieval_score=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9797fc9509084a57b864034d7114f142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker is not none, adding reranker\n",
      "Results: hit_rate: 0.9090909090909091, mrr: 0.9090909090909091\n",
      "model_to_try is: Bedrock\n",
      "reranker is: None\n",
      "Results: hit_rate: 0.9090909090909091, mrr: 0.7575757575757575\n",
      "--------------------------------------------------\n",
      "model_to_try is: Bedrock\n",
      "reranker is: Cohere\n",
      "Results: hit_rate: 0.9090909090909091, mrr: 0.9090909090909091\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mrr</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>model_name</th>\n",
       "      <th>reranker_name</th>\n",
       "      <th>embedding_time</th>\n",
       "      <th>embedding_time_single</th>\n",
       "      <th>retrieval_time</th>\n",
       "      <th>retrieval_time_single</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>BAAI/bge-reranker-base</td>\n",
       "      <td>0.881297</td>\n",
       "      <td>0.017626</td>\n",
       "      <td>0.832286</td>\n",
       "      <td>0.075662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>None</td>\n",
       "      <td>0.881297</td>\n",
       "      <td>0.017626</td>\n",
       "      <td>0.180121</td>\n",
       "      <td>0.016375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>0.881297</td>\n",
       "      <td>0.017626</td>\n",
       "      <td>11.931781</td>\n",
       "      <td>1.084707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>TurkuNLP/sbert-cased-finnish-paraphrase</td>\n",
       "      <td>BAAI/bge-reranker-base</td>\n",
       "      <td>0.788571</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.807556</td>\n",
       "      <td>0.073414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>TurkuNLP/sbert-cased-finnish-paraphrase</td>\n",
       "      <td>None</td>\n",
       "      <td>0.788571</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.187661</td>\n",
       "      <td>0.017060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>TurkuNLP/sbert-cased-finnish-paraphrase</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>0.788571</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>4.719880</td>\n",
       "      <td>0.429080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>BAAI/bge-reranker-base</td>\n",
       "      <td>2.033344</td>\n",
       "      <td>0.040667</td>\n",
       "      <td>4.105723</td>\n",
       "      <td>0.373248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>None</td>\n",
       "      <td>2.033344</td>\n",
       "      <td>0.040667</td>\n",
       "      <td>2.611783</td>\n",
       "      <td>0.237435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>2.033344</td>\n",
       "      <td>0.040667</td>\n",
       "      <td>7.966851</td>\n",
       "      <td>0.724259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>embed-multilingual-v3.0</td>\n",
       "      <td>BAAI/bge-reranker-base</td>\n",
       "      <td>2.977586</td>\n",
       "      <td>0.059552</td>\n",
       "      <td>5.075453</td>\n",
       "      <td>0.461405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>embed-multilingual-v3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2.977586</td>\n",
       "      <td>0.059552</td>\n",
       "      <td>3.702780</td>\n",
       "      <td>0.336616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>embed-multilingual-v3.0</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>2.977586</td>\n",
       "      <td>0.059552</td>\n",
       "      <td>8.602993</td>\n",
       "      <td>0.782090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>BAAI/bge-reranker-base</td>\n",
       "      <td>8.950488</td>\n",
       "      <td>0.179010</td>\n",
       "      <td>2.084496</td>\n",
       "      <td>0.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>None</td>\n",
       "      <td>8.950488</td>\n",
       "      <td>0.179010</td>\n",
       "      <td>1.270349</td>\n",
       "      <td>0.115486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>Bedrock</td>\n",
       "      <td>Cohere</td>\n",
       "      <td>8.950488</td>\n",
       "      <td>0.179010</td>\n",
       "      <td>14.442388</td>\n",
       "      <td>1.312944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mrr  hit_rate                               model_name  \\\n",
       "0  1.000000  1.000000            intfloat/multilingual-e5-base   \n",
       "0  0.954545  1.000000            intfloat/multilingual-e5-base   \n",
       "0  1.000000  1.000000            intfloat/multilingual-e5-base   \n",
       "0  1.000000  1.000000  TurkuNLP/sbert-cased-finnish-paraphrase   \n",
       "0  0.909091  1.000000  TurkuNLP/sbert-cased-finnish-paraphrase   \n",
       "0  1.000000  1.000000  TurkuNLP/sbert-cased-finnish-paraphrase   \n",
       "0  1.000000  1.000000                   text-embedding-3-small   \n",
       "0  1.000000  1.000000                   text-embedding-3-small   \n",
       "0  1.000000  1.000000                   text-embedding-3-small   \n",
       "0  1.000000  1.000000                  embed-multilingual-v3.0   \n",
       "0  0.954545  1.000000                  embed-multilingual-v3.0   \n",
       "0  1.000000  1.000000                  embed-multilingual-v3.0   \n",
       "0  0.909091  0.909091                                  Bedrock   \n",
       "0  0.757576  0.909091                                  Bedrock   \n",
       "0  0.909091  0.909091                                  Bedrock   \n",
       "\n",
       "            reranker_name  embedding_time  embedding_time_single  \\\n",
       "0  BAAI/bge-reranker-base        0.881297               0.017626   \n",
       "0                    None        0.881297               0.017626   \n",
       "0                  Cohere        0.881297               0.017626   \n",
       "0  BAAI/bge-reranker-base        0.788571               0.015771   \n",
       "0                    None        0.788571               0.015771   \n",
       "0                  Cohere        0.788571               0.015771   \n",
       "0  BAAI/bge-reranker-base        2.033344               0.040667   \n",
       "0                    None        2.033344               0.040667   \n",
       "0                  Cohere        2.033344               0.040667   \n",
       "0  BAAI/bge-reranker-base        2.977586               0.059552   \n",
       "0                    None        2.977586               0.059552   \n",
       "0                  Cohere        2.977586               0.059552   \n",
       "0  BAAI/bge-reranker-base        8.950488               0.179010   \n",
       "0                    None        8.950488               0.179010   \n",
       "0                  Cohere        8.950488               0.179010   \n",
       "\n",
       "   retrieval_time  retrieval_time_single  \n",
       "0        0.832286               0.075662  \n",
       "0        0.180121               0.016375  \n",
       "0       11.931781               1.084707  \n",
       "0        0.807556               0.073414  \n",
       "0        0.187661               0.017060  \n",
       "0        4.719880               0.429080  \n",
       "0        4.105723               0.373248  \n",
       "0        2.611783               0.237435  \n",
       "0        7.966851               0.724259  \n",
       "0        5.075453               0.461405  \n",
       "0        3.702780               0.336616  \n",
       "0        8.602993               0.782090  \n",
       "0        2.084496               0.189500  \n",
       "0        1.270349               0.115486  \n",
       "0       14.442388               1.312944  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = None\n",
    "\n",
    "Huggingface_models_to_try =[\"intfloat/multilingual-e5-base\", \"TurkuNLP/sbert-cased-finnish-paraphrase\"]\n",
    "OpenAI_models_to_try = [\"text-embedding-3-small\"]\n",
    "CohereEmbeddings = [\"embed-multilingual-v3.0\"]\n",
    "HF_rerankers_to_try = [\"BAAI/bge-reranker-base\", None]\n",
    "\n",
    "\n",
    "Eval_openAI = True\n",
    "Eval_cohere_multilingual_embeddings = True\n",
    "Eval_Bedrock_titan = True \n",
    "Eval_Cohere_rerank = True \n",
    "\n",
    "\n",
    "models_to_try = Huggingface_models_to_try\n",
    "rerankers_to_try = HF_rerankers_to_try\n",
    "\n",
    "if Eval_openAI:\n",
    "    models_to_try.extend(OpenAI_models_to_try)\n",
    "\n",
    "if Eval_cohere_multilingual_embeddings:\n",
    "    models_to_try.extend(CohereEmbeddings)\n",
    "\n",
    "if Eval_Bedrock_titan:\n",
    "    models_to_try.append(\"Bedrock\")\n",
    "\n",
    "if Eval_Cohere_rerank:\n",
    "    rerankers_to_try.append(\"Cohere\")\n",
    "\n",
    "\n",
    "# Outer loop loops over embedding models\n",
    "# Inner loop loops over rerankers\n",
    "# We need to embed data only once for inner loop,  so for when j != 0 we should not re-embed data but just change the reranker\n",
    "print(f'Using {\"cuda\" if torch.cuda.is_available() else \"cpu\"} as device')\n",
    "for i, model_to_try in enumerate(models_to_try):\n",
    "    collection_name = model_to_try.replace('/','_').replace('-','_')\n",
    "    print('-' * 50)\n",
    "    print(f\"model_to_try is: {model_to_try}\")\n",
    "    for j, reranker_name in enumerate(rerankers_to_try):\n",
    "        if j == 0:\n",
    "            print(f\"reranker is: {reranker_name}\")\n",
    "            if model_to_try in OpenAI_models_to_try:\n",
    "                embedding_model = OpenAIEmbedding(api_key=openai.api_key, model=model_to_try)\n",
    "                if reranker_name != None:\n",
    "                    if reranker_name == 'Cohere':\n",
    "                        reranker = CohereRerank(api_key=cohere_api_key, top_n=3)\n",
    "                    else:\n",
    "                        reranker = SentenceTransformerRerank(model=reranker_name, top_n=3, device='cuda:0' if torch.cuda.is_available() else 'cpu', keep_retrieval_score=True)\n",
    "                retriever, index, embedding_time, embedding_time_single = embed_data_and_def_retriever(embedding_model, reranker, collection_name)\n",
    "                retrieval_results, retrieval_time, retrieval_time_single = get_query_results(qa_dataset, retriever)\n",
    "                results_df, result_dict = form_results_df(retrieval_results, model_to_try, reranker_name, embedding_time, embedding_time_single, retrieval_time, retrieval_time_single)\n",
    "            elif model_to_try in CohereEmbeddings:\n",
    "                embedding_model = cohere_embed = CohereEmbedding(cohere_api_key=cohere_api_key, model_name=\"embed-multilingual-v3.0\", input_type=\"search_query\")\n",
    "                if reranker_name != None:\n",
    "                    if reranker_name == 'Cohere':\n",
    "                        reranker = CohereRerank(api_key=cohere_api_key, top_n=3)\n",
    "                    else:\n",
    "                        reranker = SentenceTransformerRerank(model=reranker_name, top_n=3, device='cuda:0' if torch.cuda.is_available() else 'cpu', keep_retrieval_score=True)\n",
    "                retriever, index, embedding_time, embedding_time_single = embed_data_and_def_retriever(embedding_model, reranker, collection_name)\n",
    "                retrieval_results, retrieval_time, retrieval_time_single = get_query_results(qa_dataset, retriever)\n",
    "                results_df, result_dict = form_results_df(retrieval_results, model_to_try, reranker_name, embedding_time, embedding_time_single, retrieval_time, retrieval_time_single)\n",
    "            elif model_to_try == 'Bedrock':\n",
    "                embedding_model = BedrockEmbedding(model_name='amazon.titan-embed-text-v1',client=bedrock_client)\n",
    "                if reranker_name != None:\n",
    "                    if reranker_name == 'Cohere':\n",
    "                        reranker = CohereRerank(api_key=cohere_api_key, top_n=3)\n",
    "                    else:\n",
    "                        reranker = SentenceTransformerRerank(model=reranker_name, top_n=3, device='cuda:0' if torch.cuda.is_available() else 'cpu', keep_retrieval_score=True)\n",
    "                retriever, index, embedding_time, embedding_time_single = embed_data_and_def_retriever(embedding_model, reranker, collection_name)\n",
    "                retrieval_results, retrieval_time, retrieval_time_single = get_query_results(qa_dataset, retriever)\n",
    "                results_df, result_dict = form_results_df(retrieval_results, model_to_try, reranker_name, embedding_time, embedding_time_single, retrieval_time, retrieval_time_single)\n",
    "            else:\n",
    "                embedding_model = HuggingFaceEmbedding(model_name=model_to_try, device='cuda:0' if torch.cuda.is_available() else 'cpu', max_length=512)\n",
    "                if reranker_name != None:\n",
    "                    if reranker_name == 'Cohere':\n",
    "                        reranker = CohereRerank(api_key=cohere_api_key, top_n=3)\n",
    "                    else:\n",
    "                        reranker = SentenceTransformerRerank(model=reranker_name, top_n=3, device='cuda:0' if torch.cuda.is_available() else 'cpu', keep_retrieval_score=True)\n",
    "                retriever, index, embedding_time, embedding_time_single = embed_data_and_def_retriever(embedding_model, reranker, collection_name)\n",
    "                retrieval_results, retrieval_time, retrieval_time_single = get_query_results(qa_dataset, retriever)\n",
    "                results_df, result_dict = form_results_df(retrieval_results, model_to_try, reranker_name, embedding_time, embedding_time_single, retrieval_time, retrieval_time_single)\n",
    "            print(f'Results: hit_rate: {result_dict[\"hit_rate\"]}, mrr: {result_dict[\"mrr\"]}')\n",
    "        else:\n",
    "            # Now we just need to adjust the retriever\n",
    "            print(f\"model_to_try is: {model_to_try}\")\n",
    "            print(f\"reranker is: {reranker_name}\")\n",
    "            if reranker_name != None:\n",
    "                if reranker_name == 'Cohere':\n",
    "                    reranker = CohereRerank(api_key=cohere_api_key, top_n=3)\n",
    "                    retriever = index.as_query_engine(similarity_top_k=5, node_postprocessors=[reranker])\n",
    "                else:\n",
    "                    reranker = SentenceTransformerRerank(model=reranker_name, top_n=3, device='cuda:0' if torch.cuda.is_available() else 'cpu', keep_retrieval_score=True)\n",
    "                    retriever = index.as_query_engine(similarity_top_k=5, node_postprocessors=[reranker])\n",
    "                retrieval_results, retrieval_time, retrieval_time_single = get_query_results(qa_dataset, retriever)\n",
    "                new_results, result_dict = form_results_df(retrieval_results, model_to_try, reranker_name, embedding_time, embedding_time_single, retrieval_time, retrieval_time_single)\n",
    "            else:\n",
    "                retriever = index.as_query_engine(similarity_top_k=5, node_postprocessors=None)\n",
    "                retrieval_results, retrieval_time, retrieval_time_single = get_query_results(qa_dataset, retriever)\n",
    "                new_results, result_dict = form_results_df(retrieval_results, model_to_try, reranker_name, embedding_time, embedding_time_single, retrieval_time, retrieval_time_single)\n",
    "            results_df = pd.concat([results_df, new_results])\n",
    "            \n",
    "            print(f'Results: hit_rate: {result_dict[\"hit_rate\"]}, mrr: {result_dict[\"mrr\"]}')\n",
    "            print('-' * 50)\n",
    "    if i == 0:\n",
    "        results_all = results_df\n",
    "    else:\n",
    "        results_all = pd.concat([results_all, results_df])\n",
    "results_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RagEvalEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
